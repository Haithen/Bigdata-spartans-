{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gr6YDm1rYdAJ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import lightgbm as lgb\n",
        "import gc\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import random\n",
        "import datetime as dt\n",
        "\n",
        "# Model weights\n",
        "XGB_WEIGHT = 0.6000\n",
        "BASELINE_WEIGHT = 0.0000\n",
        "OLS_WEIGHT = 0.0600\n",
        "XGB1_WEIGHT = 0.8000\n",
        "BASELINE_PRED = 0.0115\n",
        "\n",
        "def read_data():\n",
        "    print( \"\\nReading data from disk ...\")\n",
        "    prop = pd.read_csv('../input/properties_2016.csv')\n",
        "    train = pd.read_csv(\"../input/train_2016_v2.csv\")\n",
        "    return prop, train\n",
        "\n",
        "def process_data_for_lgbm(prop, train):\n",
        "    print( \"\\nProcessing data for LightGBM ...\" )\n",
        "    for c, dtype in zip(prop.columns, prop.dtypes):\t\n",
        "        if dtype == np.float64:\t\t\n",
        "            prop[c] = prop[c].astype(np.float32)\n",
        "\n",
        "    df_train = train.merge(prop, how='left', on='parcelid')\n",
        "    df_train.fillna(df_train.median(),inplace = True)\n",
        "\n",
        "    x_train = df_train.drop(['parcelid', 'logerror', 'transactiondate', 'propertyzoningdesc', \n",
        "                             'propertycountylandusecode', 'fireplacecnt', 'fireplaceflag'], axis=1)\n",
        "    y_train = df_train['logerror'].values\n",
        "    print(x_train.shape, y_train.shape)\n",
        "\n",
        "    train_columns = x_train.columns\n",
        "\n",
        "    for c in x_train.dtypes[x_train.dtypes == object].index.values:\n",
        "        x_train[c] = (x_train[c] == True)\n",
        "\n",
        "    del df_train; gc.collect()\n",
        "\n",
        "    x_train = x_train.values.astype(np.float32, copy=False)\n",
        "    d_train = lgb.Dataset(x_train, label=y_train)\n",
        "    return d_train, train_columns\n",
        "\n",
        "def lgbm_pred(d_train, train_columns):\n",
        "    params = {'max_bin': 10, 'learning_rate': 0.0021, 'boosting_type': 'gbdt', 'objective': 'regression',\n",
        "              'metric': 'l1', 'sub_feature': 0.345, 'bagging_fraction': 0.85, 'bagging_freq': 40,\n",
        "              'num_leaves': 512, 'min_data': 500, 'min_hessian': 0.05, 'verbose': 0,\n",
        "              'feature_fraction_seed': 2, 'bagging_seed': 3}\n",
        "\n",
        "    np.random.seed(0)\n",
        "    random.seed(0)\n",
        "\n",
        "    print(\"\\nFitting LightGBM model ...\")\n",
        "    clf = lgb.train(params, d_train, 430)\n",
        "\n",
        "    del d_train; gc.collect()\n",
        "\n",
        "    print(\"\\nPrepare for LightGBM prediction ...\")\n",
        "    sample = pd.read_csv('../input/sample_submission.csv')\n",
        "    sample['parcelid'] = sample['ParcelId']\n",
        "    df_test = sample.merge(prop, on='parcelid', how='left')\n",
        "\n",
        "    del sample, prop; gc.collect()\n",
        "\n",
        "    x_test = df_test[train_columns]\n",
        "    del df_test; gc.collect()\n",
        "\n",
        "    for c in x_test.dtypes[x_test.dtypes == object].index.values:\n",
        "        x_test[c] = (x_test[c] == True)\n",
        "    \n",
        "print(\"\\nTraining 2nd XGBoost ...\")\n",
        "model = xgb.train(dict(xgb_params, silent=1), dtrain, num_boost_round=num_boost_rounds)\n",
        "\n",
        "print(\"\\nPredicting with 2nd XGBoost ...\")\n",
        "xgb_pred2 = model.predict(dtest)\n",
        "\n",
        "print(\"\\nSecond XGBoost predictions:\")\n",
        "print(pd.DataFrame(xgb_pred2).head())\n",
        "\n",
        "# Combine XGBoost predictions\n",
        "xgb_pred = XGB1_WEIGHT*xgb_pred1 + (1-XGB1_WEIGHT)*xgb_pred2\n",
        "\n",
        "print(\"\\nCombined XGBoost predictions:\")\n",
        "print(pd.DataFrame(xgb_pred).head())\n",
        "\n",
        "del x_train, x_test, properties, train_df\n",
        "gc.collect()\n",
        "\n",
        "\n",
        "np.random.seed(17)\n",
        "random.seed(17)\n",
        "\n",
        "print(\"\\n\\nProcessing data for OLS ...\")\n",
        "\n",
        "# Re-read properties file\n",
        "properties = pd.read_csv('../input/properties_2016.csv')\n",
        "\n",
        "train = pd.read_csv(\"../input/train_2016_v2.csv\", parse_dates=[\"transactiondate\"])\n",
        "train = train[train.logerror > -0.4]\n",
        "train = train[train.logerror < 0.419]\n",
        "\n",
        "def get_features(df):\n",
        "    df[\"transactiondate\"] = pd.to_datetime(df[\"transactiondate\"])\n",
        "    df[\"transactiondate_year\"] = df[\"transactiondate\"].dt.year\n",
        "    df[\"transactiondate_month\"] = df[\"transactiondate\"].dt.month\n",
        "    df['transactiondate'] = df['transactiondate'].dt.quarter\n",
        "    df = df.fillna(-1.0)\n",
        "    return df\n",
        "\n",
        "def MAE(y, ypred):\n",
        "    return np.sum([abs(y[i]-ypred[i]) for i in range(len(y))]) / len(y)\n",
        "\n",
        "train = pd.merge(train, properties, how='left', on='parcelid')\n",
        "y = train['logerror'].values\n",
        "test = pd.merge(submission, properties, how='left', left_on='ParcelId', right_on='parcelid')\n",
        "properties = [] #memory\n",
        "\n",
        "exc = [train.columns[c] for c in range(len(train.columns)) if train.dtypes[c] == 'O'] + ['logerror','parcelid']\n",
        "col = [c for c in train.columns if c not in exc]\n",
        "\n",
        "train = get_features(train[col])\n",
        "test['transactiondate'] = '2016-01-01' \n",
        "test = get_features(test[col])\n",
        "\n",
        "print(\"\\nFitting OLS...\")\n",
        "reg = LinearRegression(n_jobs=-1)\n",
        "reg.fit(train, y); print('fit...')\n",
        "print(MAE(y, reg.predict(train)))\n",
        "train = [];  y = [] #memory\n",
        "\n",
        "test_dates = ['2016-10-01','2016-11-01','2016-12-01','2017-10-01','2017-11-01','2017-12-01']\n",
        "test_columns = ['201610','201611','201612','201710','201711','201712']\n",
        "\n",
        "print(\"\\nPredicting with OLS and combining with XGB and LightGBM predicitons: \")\n",
        "for i in range(len(test_dates)):\n",
        "    test['transactiondate'] = test_dates[i]\n",
        "    pred = OLS_WEIGHT*reg.predict(get_features(test)) + (1-OLS_WEIGHT)*xgb_pred\n",
        "    submission[test_columns[i]] = [float(format(x, '.4f')) for x in pred]\n",
        "    print('predict...', i)\n",
        "\n",
        "print( \"\\nCombined XGB/LGB/OLS predictions:\" )\n",
        "print( submission.head() )\n",
        "\n",
        "# Write the results\n",
        "submission.to_csv('xgb_lgb_ols.csv', index=False, float_format='%.4f')\n",
        "\n",
        "print(\"\\nFinished ...\")\n"
      ]
    }
  ]
}